{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11e79c08-2755-4c27-9a0d-0686d8992083",
   "metadata": {},
   "source": [
    "Implementation of Q-learning in python using numpy\n",
    "\n",
    "\n",
    "Q-learning is a popular reinforcement learning algorithm used to find the optimal action-selection policy for a given finite Markov decision process (MDP)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f649cd9-7e56-4d34-8c67-3d78b0d684c7",
   "metadata": {},
   "source": [
    "Import the packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20607af0-fdae-446f-87ef-f04c23fe289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cf6806-f794-4747-a5c6-0c82549d9f5a",
   "metadata": {},
   "source": [
    "Initialize parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24705df9-df8e-4254-abe6-7141671fc6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma=0.75 #Discount factor\n",
    "alpha=0.9 #Learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec7f75b-cca9-4d66-a1b6-81e1cccc88ee",
   "metadata": {},
   "source": [
    "Define the states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca1f3805-48cc-4052-a554-973d4a5eb794",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_to_state={\n",
    "    'L1':0,\n",
    "    'L2':1,\n",
    "    'L3':2,\n",
    "    'L4':3,\n",
    "    'L5':4,\n",
    "    'L6':5,\n",
    "    'L7':6,\n",
    "    'L8':7,\n",
    "    'L9':8\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb996859-b33d-4cb0-b2ed-d30b3feee462",
   "metadata": {},
   "source": [
    "Define the actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56030ea7-e75f-4e4c-b1a4-65f562c89438",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions=[0,1,2,3,4,5,6,7,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767ecb64-9325-4b18-ae91-366aaf5cc421",
   "metadata": {},
   "source": [
    "Define the rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6f87efd-21b0-4878-a529-a222e0d9d9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards=np.array([[0,1,0,0,0,0,0,0,0],\n",
    "                [1,0,1,0,0,0,0,0,0],\n",
    "                [0,1,0,0,0,1,0,0,0],\n",
    "                [0,0,0,0,0,0,1,0,0],\n",
    "                [0,1,0,0,0,0,0,1,0],\n",
    "                [0,0,1,0,0,0,0,0,0],\n",
    "                [0,0,0,1,0,0,0,1,0],\n",
    "                [0,0,0,0,1,0,1,0,1],\n",
    "                [0,0,0,0,0,0,0,1,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4334be1-95ea-4e79-929b-1898bb9574f6",
   "metadata": {},
   "source": [
    "Maps indices to locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c6631a8-67ce-4b1f-aa93-f538f8f113e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_to_location=dict((state,location) for location,state in location_to_state.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f6d61f-e288-43df-a895-8dc82d1ad877",
   "metadata": {},
   "source": [
    "Define a function get_optimal_route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93ac1e82-f968-4faa-bee1-4cbd10be6ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_route(start_location, end_location):\n",
    "    rewards_new = np.copy(rewards)\n",
    "    ending_state = location_to_state[end_location]\n",
    "    rewards_new[ending_state, ending_state] = 999  # High reward for reaching the end location\n",
    "\n",
    "    Q = np.zeros((9, 9))  # Initialize Q-values\n",
    "    for i in range(1000):\n",
    "        current_state = np.random.randint(0, 9)\n",
    "        playable_actions = [j for j in range(9) if rewards_new[current_state, j] > 0]\n",
    "        if not playable_actions:\n",
    "            continue  # Skip if no valid actions\n",
    "\n",
    "        next_state = np.random.choice(playable_actions)     \n",
    "        TD = rewards_new[current_state, next_state] + gamma * np.max(Q[next_state, :]) - Q[current_state, next_state]\n",
    "        Q[current_state, next_state] += alpha * TD\n",
    "\n",
    "    # Construct the route\n",
    "    route = [start_location]\n",
    "    next_location = start_location\n",
    "    while next_location != end_location:\n",
    "        starting_state = location_to_state[next_location]\n",
    "        next_state = np.argmax(Q[starting_state, :])\n",
    "        next_location = state_to_location[next_state]\n",
    "        route.append(next_location)\n",
    "        if next_location == end_location:\n",
    "            break\n",
    "\n",
    "    return route\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fde9071-f5a7-4990-95d0-9ec60ca511b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L9', 'L8', 'L5', 'L2', 'L1']\n"
     ]
    }
   ],
   "source": [
    "print(get_optimal_route('L9','L1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09d35f2-ee55-463f-8268-e36a4b319203",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
